Cifar10 dataset contains 60,000 color images each of size 32 pixels by 32 pixels. The images are photographs from 10 different classes such as birds, frogs, automobiles etc. The list of the 10 classes along with their integer representation is given below:

0: airplane
1: automobile
2: bird
3: cat
4: deer
5: dog
6: frog
7: horse
8: ship
9: truck

There are 50,000 images in the training dataset and 10,000 images in the test dataset. The objective is to train a neural network to classify an image into one of the 10 classes. 

Let's use a VGG model architecture. The architecture involves stacking convolutional layers with 3 X 3 filters followed by a max pooling layer. Together these layers form a block. These blocks can be repeated with the number of filters increasing with the depth of the network (32 for block 1, 64 for block 2, 128 for block 3 etc.). Padding is used to ensure that the height and width of the output matches that of the input. Each layer will use the RELU activation function. 

VGG Model with 1 block:

# Import the libraries
import sys
from keras.datasets import cifar10
from keras.utils import to_categorical 
from keras.models import Sequential 
from keras.layers import Conv2D 
from keras.layers import MaxPooling2D 
from keras.layers import Dense 
from keras.layers import Flatten 
from keras.optimizers import SGD
from matplotlib import pyplot

# Load the dataset
def load_dataset(): 
  (trainX, trainY), (testX, testY) = cifar10.load_data() 
  trainY = to_categorical(trainY) 
  testY = to_categorical(testY)
  return trainX, trainY, testX, testY

# Normalize the pixels
def prep_pixels(train, test):
  train_norm = train.astype('float32')
  test_norm = test.astype('float32')
  train_norm = train_norm / 255.0 
  test_norm = test_norm / 255.0 
  return train_norm, test_norm

# Define the model
def define_model(): 
  model = Sequential() 
  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))
  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
  model.add(MaxPooling2D((2, 2))) 
  model.add(Flatten()) 
  model.add(Dense(128, activation='relu', kernel_initializer='he_uniform')) 
  model.add(Dense(10, activation='softmax'))
  opt = SGD(lr=0.001, momentum=0.9) 
  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])
  return model
  
# Evaluate the cross entropy loss and accuracy
def summarize_diagnostics(history):
  pyplot.title('Cross Entropy Loss')
  pyplot.plot(history.history['loss'], color='blue', label='train') 
  pyplot.plot(history.history['val_loss'], color='orange', label='test') 
  pyplot.subplot(212) 
  pyplot.title('Classification Accuracy')
  pyplot.plot(history.history['acc'], color='blue', label='train')
  pyplot.plot(history.history['val_acc'], color='orange', label='test')
  filename = sys.argv[0].split('/')[-1] 
  pyplot.savefig(filename + '_plot.png') 
  pyplot.close()
  print('> %.3f' % (acc * 100.0))
  
# Creating a function that combines functions for the individual steps above  
def run_test_harness():
  trainX, trainY, testX, testY = load_dataset()
  trainX, testX = prep_pixels(trainX, testX)
  model = define_model()
  history = model.fit(trainX, trainY, epochs=100, batch_size=64, validation_data=(testX, testY), verbose=0) 
  _, acc = model.evaluate(testX, testY, verbose=0)
  print('> %.3f' % (acc * 100.0)) 
  summarize_diagnostics(history)

# Calling the function
run_test_harness()

Accuracy: 67.230
Graphs showing cross entropy loss and accuracy for train and test sets.

VGG Model with 2 blocks:

# Define the model
def define_model(): 
  model = Sequential() 
  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))
  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
  model.add(MaxPooling2D((2, 2)))
  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
  model.add(MaxPooling2D((2, 2))) 
  model.add(Flatten()) 
  model.add(Dense(128, activation='relu', kernel_initializer='he_uniform')) 
  model.add(Dense(10, activation='softmax'))
  opt = SGD(lr=0.001, momentum=0.9) 
  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])
  return model
