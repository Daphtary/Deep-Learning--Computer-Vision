
VGG Model with 1 block:

# Import the libraries
import sys
from keras.datasets import cifar10
from keras.utils import to_categorical 
from keras.models import Sequential 
from keras.layers import Conv2D 
from keras.layers import MaxPooling2D 
from keras.layers import Dense 
from keras.layers import Flatten 
from keras.optimizers import SGD
from matplotlib import pyplot

# Load the dataset
def load_dataset(): 
  (trainX, trainY), (testX, testY) = cifar10.load_data() 
  trainY = to_categorical(trainY) 
  testY = to_categorical(testY)
  return trainX, trainY, testX, testY

# Normalize the pixels
def prep_pixels(train, test):
  train_norm = train.astype('float32')
  test_norm = test.astype('float32')
  train_norm = train_norm / 255.0 
  test_norm = test_norm / 255.0 
  return train_norm, test_norm

# Define the model
def define_model(): 
  model = Sequential() 
  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))
  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
  model.add(MaxPooling2D((2, 2))) 
  model.add(Flatten()) 
  model.add(Dense(128, activation='relu', kernel_initializer='he_uniform')) 
  model.add(Dense(10, activation='softmax'))
  opt = SGD(lr=0.001, momentum=0.9) 
  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])
  return model
  
# Evaluate the cross entropy loss and accuracy
def summarize_diagnostics(history):
  pyplot.title('Cross Entropy Loss')
  pyplot.plot(history.history['loss'], color='blue', label='train') 
  pyplot.plot(history.history['val_loss'], color='orange', label='test') 
  pyplot.subplot(212) 
  pyplot.title('Classification Accuracy')
  pyplot.plot(history.history['acc'], color='blue', label='train')
  pyplot.plot(history.history['val_acc'], color='orange', label='test')
  filename = sys.argv[0].split('/')[-1] 
  pyplot.savefig(filename + '_plot.png') 
  pyplot.close()
  print('> %.3f' % (acc * 100.0))
  
# Creating a function that combines functions for the individual steps above  
def run_test_harness():
  trainX, trainY, testX, testY = load_dataset()
  trainX, testX = prep_pixels(trainX, testX)
  model = define_model()
  history = model.fit(trainX, trainY, epochs=100, batch_size=64, validation_data=(testX, testY), verbose=0) 
  _, acc = model.evaluate(testX, testY, verbose=0)
  print('> %.3f' % (acc * 100.0)) 
  summarize_diagnostics(history)

# Calling the function
run_test_harness()


